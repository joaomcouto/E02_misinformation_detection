{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = '/home/joaomcouto/git/E02_misinformation_detection/'\n",
    "MODELS_PATH = HOME_PATH + 'MM/Models/'\n",
    "TABLES_PATH = HOME_PATH\n",
    "GRAPHS_PATH = HOME_PATH + 'MM/Graphs/'\n",
    "IMAGES_PATH = HOME_PATH + 'MM/Clusters/'\n",
    "\n",
    "#N_FOLDS = 5\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "TASK_NAME = 'desinformacao_subdomain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe features e gera x combinações de tamanho r\n",
    "def random_combinations(iterable, r, x, seed=10):\n",
    "    #r é o tamanho dos modelos a serem gerados\n",
    "    #x é o numero de modelos a serem gerados\n",
    "    #iterable é o conjunto de features sobre as quais cada modelo sera definidos\n",
    "    #ps: aqui, um modelo é o conjunto de features contida nele\n",
    "    pool = tuple(iterable) #Transforma o conjunto de features numa tupla\n",
    "    n = len(pool) #n é o numero de features \n",
    "    a = [] #a vai ser uma lista de listas onde cada elemento é um modelo gerado\n",
    "    random.seed(seed) \n",
    "    for i in range(x): #Vai gerar um modelo x vezes\n",
    "        indices = sorted(random.sample(range(n), r)) #Seleciona r indices aleatorios do conjunto de features\n",
    "        a.insert(len(a), tuple(pool[i] for i in indices)) #Insere as features desses indices, em a, como um tupla\n",
    "    return list(set(a)) #Ao final \"a\" tem até x modelos unicos com r features cada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe uma lista de de modelos de mesmo tamanho encontra melhores hiperparametros para esse tamanho\n",
    "#Os hiperparametros encontrados são salvos em um arquivo\n",
    "#Isso é calculado treinando todos os modelos em comb com cada combinação de hipeparamentro e,\n",
    "# pegando a combinação de maior F1 (antes era AUC)\n",
    "def gridSearch(df, comb, c):\n",
    "    #comb é uma lista de tuplas onde cada uma é um modelo (conjunto de features)\n",
    "    #df é o dataframe com os dados (features e label) das instancias\n",
    "    #c é o tamanho dos modelos em comb\n",
    "    bestParams = {'random_state': 20200225, 'criterion': 'gini', 'max_depth': None,\n",
    "                  'min_samples_split': 71, 'min_samples_leaf': 29, 'min_impurity_decrease': 0.0}\n",
    "    bestAUC = -1\n",
    "\n",
    "    mdrange = [None, 3, 5, 10]\n",
    "    criterions = ['gini', 'entropy']\n",
    "    mssrange = list(range(5, 101, 5))\n",
    "    mslrange = list(range(5, 51, 5))\n",
    "    midrange = [0.0, 0.01, 0.1]\n",
    "    \n",
    "    #numero total de combinações de parametros que serão testados COM CADA modelo\n",
    "    combinations = len(mdrange)*len(mssrange)*len(mslrange)*len(midrange)\n",
    "\n",
    "    #Verifica se o gridsearch ja foi feito pra esse tamanho de modelo (salvo em $TASK_NAME$-size%TAMANHO%-gridsearch.pkl)\n",
    "    #Se for, \n",
    "    #coloca os parametros na lista griddone onde cada posição indice i é bestParams pra modelos tamanho i e,\n",
    "    #ja retorna o melhor conjunto de parametros.\n",
    "    if os.path.isfile(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c):\n",
    "        with open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c, 'rb') as pkldic:\n",
    "            bestParams = pickle.load(pkldic)\n",
    "            griddone[c] = combinations\n",
    "        return bestParams\n",
    "\n",
    "    tdone = 0.0\n",
    "    begin = time.time()\n",
    "    z = 0\n",
    "    for crit in criterions:\n",
    "        for md in mdrange:\n",
    "            for mss in mssrange:\n",
    "                for msl in mslrange:\n",
    "                    for mid in midrange:\n",
    "                        tdone += 1\n",
    "                        aucs = []\n",
    "                        # ff eh um modelo pq comb eh uma lista de tuplas onde cada tupla é um modelo(conjunto de features) de mesmo tamanho\n",
    "                        for ff in comb:\n",
    "                            f = []\n",
    "                            for x in ff:  # transforma a tupla com o modelo em uma lista (f)\n",
    "                                f.insert(len(f), x)\n",
    "                            auc, accmedia, preds, probs,f1,_ = select_features_platelabel(df, f,{'random_state': 1, 'max_depth': md, 'min_samples_split': mss, 'min_samples_leaf': msl, 'min_impurity_decrease': mid, 'criterion': crit}, nfolds=4,f1i=True)\n",
    "                            aucs.extend(auc)\n",
    "                            z += 1\n",
    "                            # print(z,len(comb))\n",
    "\n",
    "                        if np.mean(f1) > bestAUC:\n",
    "                            bestParams['max_depth'] = md\n",
    "                            bestParams['min_samples_split'] = mss\n",
    "                            bestParams['min_samples_leaf'] = msl\n",
    "                            bestParams['min_impurity_decrease'] = mid\n",
    "                            bestParams['criterion'] = crit\n",
    "                            bestAUC = np.mean(f1)\n",
    "\n",
    "                        if c != 0:\n",
    "                            now = time.time()\n",
    "                            elapsed = now-begin\n",
    "                            perinstance = float(elapsed)/float(tdone)\n",
    "                            predicted = perinstance * combinations\n",
    "                            griddone[c] += 1\n",
    "                            sys.stdout.write('GridSearch (size %02d) Progress: %.3f%% (%d/%d) [Elapsed: %ds | Predicted %ds | Avg: %ds]\\r' % (\n",
    "                                c, 100.0*tdone/combinations, tdone, combinations, elapsed, predicted, perinstance))\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "    with open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c, 'wb') as pkldic:\n",
    "        pickle.dump(bestParams, pkldic)\n",
    "    return(bestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe varios modelos DE MESMO TAMANHO, cada uma é uma tupla em comb\n",
    "#Efetiva ou carrega o gridsearch para o tamanho, classifica, salva resultados+preds e,\n",
    "# retorna uma lista com as aucs medias dos modelos daquele tamanho\n",
    "def eval_panel_platelabel(df, comb, c, exit_stat, exit_outp):\n",
    "    #df dado\n",
    "    #comb lista com modelos com c features\n",
    "    #exit_stat path para o csv onde resultados serão guardados \n",
    "    #exit_outp path para o csv onde predições serão guardadas \n",
    "    \n",
    "    #fpath parece ser a mesma coisa que exit_outp\n",
    "    fpath = MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-preds.csv' % c\n",
    "\n",
    "    performed = [] #Uma lista com todas as combinações de features (modelos) ja efetuados\n",
    "    \n",
    "    #Verifica se o csv com as predições ja foi criado e tem conteudo, isso indica uma execução parcial previa para esse tamanho)\n",
    "    #Sendo o caso, carrega as combinações de features ja exploradas na lista performed\n",
    "    if os.path.isfile(fpath) and os.path.getsize(fpath) > 0:\n",
    "        performed = list(pd.read_csv(\n",
    "            fpath, delimiter=';', header=0)['features'])\n",
    "        \n",
    "        #done[i] armazena o número de combinações(modelos) exploradas com i features\n",
    "        done[c] += len(performed)\n",
    "        global predone\n",
    "        #predone armazena o número total de combinações que já haviam sido exploradas (encontradas no csv)\n",
    "        predone += len(performed)\n",
    "        \n",
    "        #assegura que os proximos resultados e predições serão appendados numa nova linha\n",
    "        exit_outp.write('\\n')\n",
    "        exit_stat.write('\\n')\n",
    "        \n",
    "    #Não sendo o caso estruturamos os headers (primeira linha)do csv para receber as predições e probabilidades,\n",
    "    #de cada instancia no dado (df)\n",
    "    else:\n",
    "        exit_outp.write('features')\n",
    "        for i in range(len(df)):\n",
    "            exit_outp.write(';pred%d' % (i+1))\n",
    "        for i in range(len(df)):\n",
    "            exit_outp.write(';prob%d' % (i+1))\n",
    "        exit_outp.write('\\n')\n",
    "\n",
    "    #Faz o gridsearch usando até 50 modelos daquele tamanho\n",
    "    params = gridSearch(df, comb[:max(50, int(0.001*float(len(comb))))], c)\n",
    "\n",
    "    ncomb = [] #Sera uma list com os modelos em comb a menos daqueles que já foram explorados (estao em performed)\n",
    "    begin = time.time()\n",
    "    tdone = 0.0 #Armazena o total de novas combinações exploradas (não estavam em performed e foram efetivadas)\n",
    "\n",
    "    for ff in comb:\n",
    "        f = []\n",
    "        for x in ff:  # transforma a tupla com o modelo em uma lista só pra conseguir ver se ta no performed\n",
    "            f.insert(len(f), x)\n",
    "\n",
    "        if str(f) not in performed:\n",
    "            ncomb.append(ff)\n",
    "            \n",
    "    comb = ncomb\n",
    "    res = []\n",
    "    # ff eh um modelo pois comb eh uma lista de tuplas onde cada tupla é um modelo(conjunto de features) de mesmo tamanho\n",
    "    #lembrando que comb foi atualizado para conter apenas as combinações que já não estavam em performed\n",
    "    for ff in comb:\n",
    "        tdone += 1\n",
    "        now = time.time()\n",
    "        elapsed = now-begin\n",
    "        perinstance = float(elapsed)/float(tdone) #Tempo médio gasto em cada combinação\n",
    "        predicted = perinstance * len(comb) #Tempo estimado até o fim de todas as combinações DESSE TAMANHO\n",
    "        sys.stdout.write('MM (size %02d) Progress: %.3f%% (%d/%d) [Elapsed: %ds | Predicted %ds | Avg: %ds]\\r' % (\n",
    "            c, 100.0*tdone/len(comb), tdone, len(comb), elapsed, predicted, perinstance))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        global s #Variavel global que define o número maximos de modelos que exploraremos pra um tamanho\n",
    "                    #Até segunda ordem setado em 10000\n",
    "                        #Necessario pous com um tamanho elevado de features as combinações possiveis são MUITA\n",
    "                            #Nao precisamos explorar mais que s\n",
    "        if done[c] > s: \n",
    "            break\n",
    "\n",
    "        f = []\n",
    "        for x in ff:  # transforma a tupla com o modelo em uma lista\n",
    "            f.insert(len(f), x)\n",
    "        auc, accmedia, preds, probs, f1, f1w = select_features_platelabel(\n",
    "            df, f, params, nfolds=N_FOLDS, f1i=True)  # Chama a funcao central de treinamento p/ modelo f\n",
    "        done[c] += 1\n",
    "        res.append(np.mean(auc))\n",
    "        exit_stat.write(\"%s;%f;%f;%f;%s;%s;%s;%s\\n\" %\n",
    "                        (str(f), np.mean(auc),np.mean(f1),np.mean(f1w),auc,f1,f1w,accmedia))\n",
    "\n",
    "        exit_outp.write(\"%s\" % str(f))\n",
    "        for p in preds:\n",
    "            exit_outp.write(';%d' % p)\n",
    "        for p in probs:\n",
    "            exit_outp.write(';%f' % p)\n",
    "        exit_outp.write('\\n')\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_last_lines(ifile):\n",
    "    with open(ifile, \"r+\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        # Move the pointer (similar to a cursor in a text editor) to the end of the file\n",
    "        file.seek(0, os.SEEK_END)\n",
    "\n",
    "        # This code means the following code skips the very last character in the file -\n",
    "        # i.e. in the case the last line is null we delete the last line\n",
    "        # and the penultimate one\n",
    "        pos = file.tell() - 1\n",
    "\n",
    "        # Read each character in the file one at a time from the penultimate\n",
    "        # character going backwards, searching for a newline character\n",
    "        # If we find a new line, exit the search\n",
    "        while pos > 0 and file.read(1) != \"\\n\":\n",
    "            pos -= 1\n",
    "            file.seek(pos, os.SEEK_SET)\n",
    "\n",
    "        # So long as we're not at the start of the file, delete all the characters ahead\n",
    "        # of this position\n",
    "        if pos > 0:\n",
    "            file.seek(pos, os.SEEK_SET)\n",
    "            file.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe UM modelo/parametros de decision tree e retorna scores, predições\n",
    "# Retorna: aucs por fold, média de acuracia nos folds,\n",
    "def select_features_platelabel(df, features, params, nfolds, f1i=False):  \n",
    "    #\n",
    "\n",
    "    X = df[features].values\n",
    "    y = df[label_column_name].values\n",
    "    predList = np.zeros(len(df))\n",
    "    probList = np.zeros(len(df))\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=1)\n",
    "    foldNum = 0\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    for (train, val) in cv.split(X, y):\n",
    "        #print(np.sum(y[train]),np.sum(y[val],len(y))\n",
    "        foldNum = foldNum + 1\n",
    "\n",
    "        # Modelo arvore\n",
    "        classifier = DecisionTreeClassifier(class_weight='balanced', \n",
    "                                            max_depth=params['max_depth'], \n",
    "                                            min_samples_leaf=params['min_samples_leaf'],\n",
    "                                            min_samples_split=params['min_samples_split'], \n",
    "                                            min_impurity_decrease=params['min_impurity_decrease'], \n",
    "                                            criterion=params['criterion'])\n",
    "        classifier = classifier.fit(X[train], y[train])\n",
    "        probas_ = classifier.predict_proba(X[val])\n",
    "        \n",
    "        #Extraimos[0] pois predict_proba retorna uma coluna pra cada classe, pegamos as probabilidades da 0\n",
    "        probas = [probas_[x][0] for x in range(len(probas_))]\n",
    "\n",
    "        pred = classifier.predict(X[val])\n",
    "        area1 = roc_auc_score(y[val], probas_[:, 1])\n",
    "        area2 = accuracy_score(y[val], pred)  # guarda acuracia\n",
    "\n",
    "        #print('b',np.sum(y[val]),np.sum(pred),len(y[val]))\n",
    "        f1 = f1_score(y[val],pred, average='binary')\n",
    "        #print('w',np.sum(y[val]),np.sum(pred),len(y[val]))\n",
    "        f1w = f1_score(y[val],pred, average='weighted')\n",
    "        \n",
    "        #a guarda o AUC score de cada fold\n",
    "        a.insert(len(a), area1)\n",
    "        #b guarda a acuraria score de cada fold\n",
    "        b.insert(len(b), area2)\n",
    "        #c guarda o F1-binary score de cada fold\n",
    "        c.insert(len(c),f1)\n",
    "        #d guarda o F1-weighted score de cada fold\n",
    "        d.insert(len(d),f1w)\n",
    "\n",
    "        for j in range(len(val)):\n",
    "            #Como cada instancia em df vai estar no conjunto de val em algum fold,\n",
    "            #predlist armazena as predições para todos eles em seus respectivos folds\n",
    "            #probLIst armazena as probabilidades para todos eles em seus respectivos folds\n",
    "            \n",
    "            #val[i] contem o indice em X da i-esima instancia atualmente na validação\n",
    "            #Assim se a instancia indice 3 do dataframe é o primeiro elemento no conjunto de validação atual,\n",
    "            #  estamos fazendo predList[3] = pred[0] já que pred é indexado na ordem de val\n",
    "            predList[val[j]] = pred[j]\n",
    "            probList[val[j]] = probas[j]\n",
    "\n",
    "    if f1i:\n",
    "        return a, np.mean(b), predList, probList,c,d\n",
    "    return a, np.mean(b), predList, probList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(TABLES_PATH + 'totalcx7.csv')\n",
    "df = pd.read_pickle(\"./dfSubdomainSourceFeatures22Apr2021.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desinformacao_label</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>subdomain_ip</th>\n",
       "      <th>subdomain_ip_cc</th>\n",
       "      <th>subdomain_ip_is_brazil</th>\n",
       "      <th>subdomain_ip_is_us</th>\n",
       "      <th>subdomain_ip_latitude</th>\n",
       "      <th>subdomain_ip_longitude</th>\n",
       "      <th>subdomain_as_n</th>\n",
       "      <th>subdomain_as_cc</th>\n",
       "      <th>subdomain_ipcc_equal_ascc</th>\n",
       "      <th>domain_route_hops</th>\n",
       "      <th>domain_dns_caa_txt_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>josiasdesouza.blogosfera.uol.com.br</td>\n",
       "      <td>2600:9000:20aa:8000:15:17d9:d540:93a1</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>16509</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>agorarn.com.br</td>\n",
       "      <td>170.81.43.64</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-26.96</td>\n",
       "      <td>-52.54</td>\n",
       "      <td>266400</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>correio24horas.com.br</td>\n",
       "      <td>204.199.44.209</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.92</td>\n",
       "      <td>-43.95</td>\n",
       "      <td>3549</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tribunaonline.com.br</td>\n",
       "      <td>35.201.90.53</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>39.11</td>\n",
       "      <td>-94.54</td>\n",
       "      <td>15169</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>correiodopovo.com.br</td>\n",
       "      <td>189.16.116.12</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-30.04</td>\n",
       "      <td>-51.23</td>\n",
       "      <td>4230</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  desinformacao_label                            subdomain  \\\n",
       "0                   0  josiasdesouza.blogosfera.uol.com.br   \n",
       "1                   0                       agorarn.com.br   \n",
       "2                   0                correio24horas.com.br   \n",
       "3                   0                 tribunaonline.com.br   \n",
       "4                   0                 correiodopovo.com.br   \n",
       "\n",
       "                            subdomain_ip subdomain_ip_cc  \\\n",
       "0  2600:9000:20aa:8000:15:17d9:d540:93a1              US   \n",
       "1                           170.81.43.64              BR   \n",
       "2                         204.199.44.209              BR   \n",
       "3                           35.201.90.53              US   \n",
       "4                          189.16.116.12              BR   \n",
       "\n",
       "  subdomain_ip_is_brazil subdomain_ip_is_us subdomain_ip_latitude  \\\n",
       "0                  False               True                 34.06   \n",
       "1                   True              False                -26.96   \n",
       "2                   True              False                -19.92   \n",
       "3                  False               True                 39.11   \n",
       "4                   True              False                -30.04   \n",
       "\n",
       "  subdomain_ip_longitude subdomain_as_n subdomain_as_cc  \\\n",
       "0                -118.25          16509              US   \n",
       "1                 -52.54         266400              BR   \n",
       "2                 -43.95           3549              US   \n",
       "3                 -94.54          15169              US   \n",
       "4                 -51.23           4230              BR   \n",
       "\n",
       "  subdomain_ipcc_equal_ascc domain_route_hops domain_dns_caa_txt_count  \n",
       "0                      True                12                       59  \n",
       "1                      True                17                        2  \n",
       "2                     False                12                        3  \n",
       "3                      True                14                        2  \n",
       "4                      True                14                        7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desinformacao_label</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>subdomain_ip</th>\n",
       "      <th>subdomain_ip_cc</th>\n",
       "      <th>subdomain_ip_is_brazil</th>\n",
       "      <th>subdomain_ip_is_us</th>\n",
       "      <th>subdomain_ip_latitude</th>\n",
       "      <th>subdomain_ip_longitude</th>\n",
       "      <th>subdomain_as_n</th>\n",
       "      <th>subdomain_as_cc</th>\n",
       "      <th>subdomain_ipcc_equal_ascc</th>\n",
       "      <th>domain_route_hops</th>\n",
       "      <th>domain_dns_caa_txt_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>josiasdesouza.blogosfera.uol.com.br</td>\n",
       "      <td>2600:9000:20aa:8000:15:17d9:d540:93a1</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>16509</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>agorarn.com.br</td>\n",
       "      <td>170.81.43.64</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-26.96</td>\n",
       "      <td>-52.54</td>\n",
       "      <td>266400</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>correio24horas.com.br</td>\n",
       "      <td>204.199.44.209</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.92</td>\n",
       "      <td>-43.95</td>\n",
       "      <td>3549</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tribunaonline.com.br</td>\n",
       "      <td>35.201.90.53</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>39.11</td>\n",
       "      <td>-94.54</td>\n",
       "      <td>15169</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>correiodopovo.com.br</td>\n",
       "      <td>189.16.116.12</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-30.04</td>\n",
       "      <td>-51.23</td>\n",
       "      <td>4230</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  desinformacao_label                            subdomain  \\\n",
       "0                   0  josiasdesouza.blogosfera.uol.com.br   \n",
       "1                   0                       agorarn.com.br   \n",
       "2                   0                correio24horas.com.br   \n",
       "3                   0                 tribunaonline.com.br   \n",
       "4                   0                 correiodopovo.com.br   \n",
       "\n",
       "                            subdomain_ip subdomain_ip_cc  \\\n",
       "0  2600:9000:20aa:8000:15:17d9:d540:93a1              US   \n",
       "1                           170.81.43.64              BR   \n",
       "2                         204.199.44.209              BR   \n",
       "3                           35.201.90.53              US   \n",
       "4                          189.16.116.12              BR   \n",
       "\n",
       "  subdomain_ip_is_brazil subdomain_ip_is_us subdomain_ip_latitude  \\\n",
       "0                  False               True                 34.06   \n",
       "1                   True              False                -26.96   \n",
       "2                   True              False                -19.92   \n",
       "3                  False               True                 39.11   \n",
       "4                   True              False                -30.04   \n",
       "\n",
       "  subdomain_ip_longitude subdomain_as_n subdomain_as_cc  \\\n",
       "0                -118.25          16509              US   \n",
       "1                 -52.54         266400              BR   \n",
       "2                 -43.95           3549              US   \n",
       "3                 -94.54          15169              US   \n",
       "4                 -51.23           4230              BR   \n",
       "\n",
       "  subdomain_ipcc_equal_ascc domain_route_hops domain_dns_caa_txt_count  \n",
       "0                      True                12                       59  \n",
       "1                      True                17                        2  \n",
       "2                     False                12                        3  \n",
       "3                      True                14                        2  \n",
       "4                      True                14                        7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['desinformacao_label', 'subdomain', 'subdomain_ip', 'subdomain_ip_cc',\n",
       "       'subdomain_ip_is_brazil', 'subdomain_ip_is_us', 'subdomain_ip_latitude',\n",
       "       'subdomain_ip_longitude', 'subdomain_as_n', 'subdomain_as_cc',\n",
       "       'subdomain_ipcc_equal_ascc', 'domain_route_hops',\n",
       "       'domain_dns_caa_txt_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desinformacao_label']= df['desinformacao_label'].astype('bool')\n",
    "df['subdomain_ip_cc']= df['subdomain_ip_cc'].astype('category')\n",
    "df['subdomain_ip_is_brazil']= df['subdomain_ip_is_brazil'].astype('bool')\n",
    "df['subdomain_ip_is_us']= df['subdomain_ip_is_us'].astype('bool')\n",
    "df['subdomain_ip_latitude']= df['subdomain_ip_latitude'].astype('float')\n",
    "df['subdomain_ip_longitude']= df['subdomain_ip_longitude'].astype('float')\n",
    "df['subdomain_as_n']= df['subdomain_as_n'].astype('category')\n",
    "df['subdomain_as_cc']= df['subdomain_as_cc'].astype('category')\n",
    "df['subdomain_ipcc_equal_ascc']= df['subdomain_ipcc_equal_ascc'].astype('bool')\n",
    "df['domain_route_hops']= df['domain_route_hops'].astype('int')\n",
    "df['domain_dns_caa_txt_count']= df['domain_dns_caa_txt_count'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['10796', '11921', '12876', '13335', '13414', '134548',\n",
       "                  '14061', '14618', '15169', '16276', '16509', '16625',\n",
       "                  '19318', '20044', '20446', '20473', '206834', '20940',\n",
       "                  '22548', '22612', '262651', '262706', '26337', '2635',\n",
       "                  '263511', '26592', '266400', '266444', '270797', '27715',\n",
       "                  '28209', '28250', '28299', '28604', '29802', '30083',\n",
       "                  '30148', '30475', '30633', '32934', '3549', '35717',\n",
       "                  '396982', '398101', '40444', '4230', '42336', '44066',\n",
       "                  '46606', '47583', '51468', '52580', '53055', '53066',\n",
       "                  '54113', '56732', '61946', '63068', '7162', '8075', '8167',\n",
       "                  '8452'],\n",
       ", ordered=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes['subdomain_as_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 382 entries, 0 to 381\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   desinformacao_label        382 non-null    bool    \n",
      " 1   subdomain                  382 non-null    object  \n",
      " 2   subdomain_ip               382 non-null    object  \n",
      " 3   subdomain_ip_cc            382 non-null    category\n",
      " 4   subdomain_ip_is_brazil     382 non-null    bool    \n",
      " 5   subdomain_ip_is_us         382 non-null    bool    \n",
      " 6   subdomain_ip_latitude      382 non-null    float64 \n",
      " 7   subdomain_ip_longitude     382 non-null    float64 \n",
      " 8   subdomain_as_n             382 non-null    category\n",
      " 9   subdomain_as_cc            382 non-null    category\n",
      " 10  subdomain_ipcc_equal_ascc  382 non-null    bool    \n",
      " 11  domain_route_hops          382 non-null    int64   \n",
      " 12  domain_dns_caa_txt_count   382 non-null    int64   \n",
      "dtypes: bool(4), category(3), float64(2), int64(2), object(2)\n",
      "memory usage: 27.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 277\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "label_column_name = 'desinformacao_label'\n",
    "numericalFeatures = ['subdomain_ip_latitude', 'subdomain_ip_longitude','domain_route_hops','domain_dns_caa_txt_count']\n",
    "categorialFeatures = ['subdomain_ip_cc','subdomain_ip_is_brazil','subdomain_ip_is_us', \n",
    "                      'subdomain_as_cc', 'subdomain_ipcc_equal_ascc']\n",
    "nonFeatures = ['subdomain', 'subdomain_ip','subdomain_as_n' ]\n",
    "\n",
    "\n",
    "\n",
    "columns = list(df.columns)\n",
    "\n",
    "\n",
    "unwanted_columns = [label_column_name]+nonFeatures + categorialFeatures \n",
    "features_columns = [\n",
    "    item for item in columns if item not in unwanted_columns\n",
    "                   ]\n",
    "print(len(df), np.sum(df[label_column_name]))\n",
    "print(len(features_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature Combinations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global done\n",
    "global griddone\n",
    "global predone\n",
    "global queue_finished\n",
    "queue_finished = 0\n",
    "predone = 0\n",
    "global s\n",
    "#s = 10000\n",
    "s = 5\n",
    "totalmodels = 0\n",
    "combs = []\n",
    "done = []\n",
    "griddone = []\n",
    "\n",
    "print('Creating Feature Combinations')\n",
    "numeroMaximoDeFeatures = len(features_columns)\n",
    "for c in range(0,numeroMaximoDeFeatures+1 ):\n",
    "    # print('\\t Size:%d'%c)\n",
    "    if c == 0:\n",
    "        combs.append([])\n",
    "    else:\n",
    "        combs.append(list(set(random_combinations(features_columns, c, s))))\n",
    "    done.append(0)\n",
    "    griddone.append(0)\n",
    "    totalmodels += len(combs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mmpool(c):\n",
    "    sys.stdout.write(\"Starting MM size %d\\n\" % c)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    comb = combs[c]\n",
    "    \n",
    "    exit1 = open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                 '-size%d-result.csv' % c, 'a+')\n",
    "    exit2 = open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                 '-size%d-preds.csv' % c, 'a+')\n",
    "\n",
    "    a = eval_panel_platelabel(df, comb, c, exit1, exit2)\n",
    "\n",
    "    global queue_finished\n",
    "    queue_finished += 1\n",
    "    exit1.close()\n",
    "    exit2.close()\n",
    "    return(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directories\n",
      "Starting MM size 1\n",
      "Starting MM size 2ess: 100.000% (3/3) [Elapsed: 0s | Predicted 0s | Avg: 0s]\n",
      "0.6843846629560915ess: 100.000% (4/4) [Elapsed: 0s | Predicted 0s | Avg: 0s]\n",
      "0.7981539888682745\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    print('Creating Directories')\n",
    "    if (not os.path.isdir(MODELS_PATH + 'MultipleModels_DecisionTrees')):\n",
    "        os.mkdir(MODELS_PATH + 'MultipleModels_DecisionTrees')\n",
    "\n",
    "    #for c in range(1, numeroMaximoDeFeatures+1):\n",
    "    #Deletamos a ultima linha pro caso de ter rolado uma execução parcial\n",
    "    for c in range(1, 3):\n",
    "        if os.path.isfile('MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-result.csv' % c):\n",
    "            delete_last_lines('MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                              '-size%d-result.csv' % c)\n",
    "            delete_last_lines('MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                              '-size%d-preds.csv' % c)\n",
    "    results = []\n",
    "    for c in range(1,3):\n",
    "        res = run_mmpool(c)\n",
    "        results.append(res)\n",
    "        \n",
    "        \n",
    "#     pool = Pool(processes=10)\n",
    "#     #results = pool.map(run_mmpool, list(range(1, numeroMaximoDeFeatures+1)))\n",
    "#     results = pool.map(run_mmpool, list(range(1, 3)))\n",
    "#     time.sleep(10)\n",
    "#     pool.join()\n",
    "\n",
    "for i in range(0, len(results)):\n",
    "    print(np.max(results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

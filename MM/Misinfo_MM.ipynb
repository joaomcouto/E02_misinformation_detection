{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = '/home/joaomcouto/git/E02_misinformation_detection/'\n",
    "MODELS_PATH = HOME_PATH + 'MM/Models/'\n",
    "TABLES_PATH = HOME_PATH\n",
    "GRAPHS_PATH = HOME_PATH + 'MM/Graphs/'\n",
    "IMAGES_PATH = HOME_PATH + 'MM/Clusters/'\n",
    "\n",
    "#N_FOLDS = 5\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "TASK_NAME = 'desinformacao_urls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe features e gera x combinações de tamanho r\n",
    "def random_combinations(iterable, r, x, seed=10):\n",
    "    #r é o tamanho dos modelos a serem gerados\n",
    "    #x é o numero de modelos a serem gerados\n",
    "    #iterable é o conjunto de features sobre as quais cada modelo sera definidos\n",
    "    #ps: aqui, um modelo é o conjunto de features contida nele\n",
    "    pool = tuple(iterable) #Transforma o conjunto de features numa tupla\n",
    "    n = len(pool) #n é o numero de features \n",
    "    a = [] #a vai ser uma lista de listas onde cada elemento é um modelo gerado\n",
    "    random.seed(seed) \n",
    "    for i in range(x): #Vai gerar um modelo x vezes\n",
    "        indices = sorted(random.sample(range(n), r)) #Seleciona r indices aleatorios do conjunto de features\n",
    "        a.insert(len(a), tuple(pool[i] for i in indices)) #Insere as features desses indices, em a, como um tupla\n",
    "    return list(set(a)) #Ao final \"a\" tem até x modelos unicos com r features cada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe uma lista de de modelos de mesmo tamanho encontra melhores hiperparametros para esse tamanho\n",
    "#Os hiperparametros encontrados são salvos em um arquivo\n",
    "#Isso é calculado treinando todos os modelos em comb com cada combinação de hipeparamentro e,\n",
    "# pegando a combinação de maior F1 (antes era AUC)\n",
    "def gridSearch(df, comb, c):\n",
    "    #comb é uma lista de tuplas onde cada uma é um modelo (conjunto de features)\n",
    "    #df é o dataframe com os dados (features e label) das instancias\n",
    "    #c é o tamanho dos modelos em comb\n",
    "    bestParams = {'random_state': 20200225, 'criterion': 'gini', 'max_depth': None,\n",
    "                  'min_samples_split': 71, 'min_samples_leaf': 29, 'min_impurity_decrease': 0.0}\n",
    "    bestAUC = -1\n",
    "\n",
    "    mdrange = [None, 3, 5, 10]\n",
    "    criterions = ['gini', 'entropy']\n",
    "    mssrange = list(range(5, 101, 5))\n",
    "    mslrange = list(range(5, 51, 5))\n",
    "    midrange = [0.0, 0.01, 0.1]\n",
    "    \n",
    "    #numero total de combinações de parametros que serão testados COM CADA modelo\n",
    "    combinations = len(mdrange)*len(mssrange)*len(mslrange)*len(midrange)*len(criterions)\n",
    "\n",
    "    #Verifica se o gridsearch ja foi feito pra esse tamanho de modelo (salvo em $TASK_NAME$-size%TAMANHO%-gridsearch.pkl)\n",
    "    #Se for, \n",
    "    #coloca os parametros na lista griddone onde cada posição indice i é bestParams pra modelos tamanho i e,\n",
    "    #ja retorna o melhor conjunto de parametros.\n",
    "    if os.path.isfile(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c):\n",
    "        with open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c, 'rb') as pkldic:\n",
    "            bestParams = pickle.load(pkldic)\n",
    "            griddone[c] = combinations\n",
    "        return bestParams\n",
    "\n",
    "    tdone = 0.0\n",
    "    begin = time.time()\n",
    "    z = 0\n",
    "    for crit in criterions:\n",
    "        for md in mdrange:\n",
    "            for mss in mssrange:\n",
    "                for msl in mslrange:\n",
    "                    for mid in midrange:\n",
    "                        tdone += 1\n",
    "                        aucs = []\n",
    "                        # ff eh um modelo pq comb eh uma lista de tuplas onde cada tupla é um modelo(conjunto de features) de mesmo tamanho\n",
    "                        for ff in comb:\n",
    "                            f = []\n",
    "                            for x in ff:  # transforma a tupla com o modelo em uma lista (f)\n",
    "                                f.insert(len(f), x)\n",
    "                            auc, accmedia, preds, probs,f1,_ = select_features_platelabel(df, f,{'random_state': 1, 'max_depth': md, 'min_samples_split': mss, 'min_samples_leaf': msl, 'min_impurity_decrease': mid, 'criterion': crit}, nfolds=4,f1i=True)\n",
    "                            aucs.extend(auc)\n",
    "                            z += 1\n",
    "                            # print(z,len(comb))\n",
    "\n",
    "                        if np.mean(f1) > bestAUC:\n",
    "                            bestParams['max_depth'] = md\n",
    "                            bestParams['min_samples_split'] = mss\n",
    "                            bestParams['min_samples_leaf'] = msl\n",
    "                            bestParams['min_impurity_decrease'] = mid\n",
    "                            bestParams['criterion'] = crit\n",
    "                            bestAUC = np.mean(f1)\n",
    "\n",
    "                        if c != 0:\n",
    "                            now = time.time()\n",
    "                            elapsed = now-begin\n",
    "                            perinstance = float(elapsed)/float(tdone)\n",
    "                            predicted = perinstance * combinations\n",
    "                            griddone[c] += 1\n",
    "                            sys.stdout.write('GridSearch (size %02d) Progress: %.3f%% (%d/%d) [Elapsed: %ds | Predicted %ds | Avg: %ds]\\r' % (\n",
    "                                c, 100.0*tdone/combinations, tdone, combinations, elapsed, predicted, perinstance))\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "    with open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-gridsearch.pkl' % c, 'wb') as pkldic:\n",
    "        pickle.dump(bestParams, pkldic)\n",
    "    return(bestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe varios modelos DE MESMO TAMANHO, cada uma é uma tupla em comb\n",
    "#Efetiva ou carrega o gridsearch para o tamanho, classifica, salva resultados+preds e,\n",
    "# retorna uma lista com as aucs medias dos modelos daquele tamanho\n",
    "def eval_panel_platelabel(df, comb, c, exit_stat, exit_outp):\n",
    "    #df dado\n",
    "    #comb lista com modelos com c features\n",
    "    #exit_stat path para o csv onde resultados serão guardados \n",
    "    #exit_outp path para o csv onde predições serão guardadas \n",
    "    \n",
    "    #fpath parece ser a mesma coisa que exit_outp\n",
    "    fpath = MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-preds.csv' % c\n",
    "\n",
    "    performed = [] #Uma lista com todas as combinações de features (modelos) ja efetuados\n",
    "    \n",
    "    #Verifica se o csv com as predições ja foi criado e tem conteudo, isso indica uma execução parcial previa para esse tamanho)\n",
    "    #Sendo o caso, carrega as combinações de features ja exploradas na lista performed\n",
    "    if os.path.isfile(fpath) and os.path.getsize(fpath) > 0:\n",
    "        performed = list(pd.read_csv(\n",
    "            fpath, delimiter=';', header=0)['features'])\n",
    "        \n",
    "        #done[i] armazena o número de combinações(modelos) exploradas com i features\n",
    "        done[c] += len(performed)\n",
    "        global predone\n",
    "        #predone armazena o número total de combinações que já haviam sido exploradas (encontradas no csv)\n",
    "        predone += len(performed)\n",
    "        \n",
    "        #assegura que os proximos resultados e predições serão appendados numa nova linha\n",
    "        exit_outp.write('\\n')\n",
    "        exit_stat.write('\\n')\n",
    "        \n",
    "    #Não sendo o caso estruturamos os headers (primeira linha)do csv para receber as predições e probabilidades,\n",
    "    #de cada instancia no dado (df)\n",
    "    else:\n",
    "        exit_outp.write('features')\n",
    "        for i in range(len(df)):\n",
    "            exit_outp.write(';pred%d' % (i+1))\n",
    "        for i in range(len(df)):\n",
    "            exit_outp.write(';prob%d' % (i+1))\n",
    "        exit_outp.write('\\n')\n",
    "\n",
    "    #Faz o gridsearch usando até 50 modelos daquele tamanho\n",
    "    params = gridSearch(df, comb[:max(50, int(0.001*float(len(comb))))], c)\n",
    "\n",
    "    ncomb = [] #Sera uma list com os modelos em comb a menos daqueles que já foram explorados (estao em performed)\n",
    "    begin = time.time()\n",
    "    tdone = 0.0 #Armazena o total de novas combinações exploradas (não estavam em performed e foram efetivadas)\n",
    "\n",
    "    for ff in comb:\n",
    "        f = []\n",
    "        for x in ff:  # transforma a tupla com o modelo em uma lista só pra conseguir ver se ta no performed\n",
    "            f.insert(len(f), x)\n",
    "\n",
    "        if str(f) not in performed:\n",
    "            ncomb.append(ff)\n",
    "            \n",
    "    comb = ncomb\n",
    "    res = []\n",
    "    # ff eh um modelo pois comb eh uma lista de tuplas onde cada tupla é um modelo(conjunto de features) de mesmo tamanho\n",
    "    #lembrando que comb foi atualizado para conter apenas as combinações que já não estavam em performed\n",
    "    for ff in comb:\n",
    "        tdone += 1\n",
    "        now = time.time()\n",
    "        elapsed = now-begin\n",
    "        perinstance = float(elapsed)/float(tdone) #Tempo médio gasto em cada combinação\n",
    "        predicted = perinstance * len(comb) #Tempo estimado até o fim de todas as combinações DESSE TAMANHO\n",
    "        sys.stdout.write('MM (size %02d) Progress: %.3f%% (%d/%d) [Elapsed: %ds | Predicted %ds | Avg: %ds]\\r' % (\n",
    "            c, 100.0*tdone/len(comb), tdone, len(comb), elapsed, predicted, perinstance))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        global s #Variavel global que define o número maximos de modelos que exploraremos pra um tamanho\n",
    "                    #Até segunda ordem setado em 10000\n",
    "                        #Necessario pous com um tamanho elevado de features as combinações possiveis são MUITA\n",
    "                            #Nao precisamos explorar mais que s\n",
    "        if done[c] > s: \n",
    "            break\n",
    "\n",
    "        f = []\n",
    "        for x in ff:  # transforma a tupla com o modelo em uma lista\n",
    "            f.insert(len(f), x)\n",
    "        auc, accmedia, preds, probs, f1, f1w = select_features_platelabel(\n",
    "            df, f, params, nfolds=N_FOLDS, f1i=True)  # Chama a funcao central de treinamento p/ modelo f\n",
    "        done[c] += 1\n",
    "        res.append(np.mean(auc))\n",
    "        exit_stat.write(\"%s;%f;%f;%f;%s;%s;%s;%s\\n\" %\n",
    "                        (str(f), np.mean(auc),np.mean(f1),np.mean(f1w),auc,f1,f1w,accmedia))\n",
    "\n",
    "        exit_outp.write(\"%s\" % str(f))\n",
    "        for p in preds:\n",
    "            exit_outp.write(';%d' % p)\n",
    "        for p in probs:\n",
    "            exit_outp.write(';%f' % p)\n",
    "        exit_outp.write('\\n')\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_last_lines(ifile):\n",
    "    with open(ifile, \"r+\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        # Move the pointer (similar to a cursor in a text editor) to the end of the file\n",
    "        file.seek(0, os.SEEK_END)\n",
    "\n",
    "        # This code means the following code skips the very last character in the file -\n",
    "        # i.e. in the case the last line is null we delete the last line\n",
    "        # and the penultimate one\n",
    "        pos = file.tell() - 1\n",
    "\n",
    "        # Read each character in the file one at a time from the penultimate\n",
    "        # character going backwards, searching for a newline character\n",
    "        # If we find a new line, exit the search\n",
    "        while pos > 0 and file.read(1) != \"\\n\":\n",
    "            pos -= 1\n",
    "            file.seek(pos, os.SEEK_SET)\n",
    "\n",
    "        # So long as we're not at the start of the file, delete all the characters ahead\n",
    "        # of this position\n",
    "        if pos > 0:\n",
    "            file.seek(pos, os.SEEK_SET)\n",
    "            file.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe UM modelo/parametros de decision tree e retorna scores, predições\n",
    "# Retorna: aucs por fold, média de acuracia nos folds,\n",
    "def select_features_platelabel(df, features, params, nfolds, f1i=False):  \n",
    "    #\n",
    "\n",
    "    X = df[features].values\n",
    "    y = df[label_column_name].values\n",
    "    predList = np.zeros(len(df))\n",
    "    probList = np.zeros(len(df))\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=1)\n",
    "    foldNum = 0\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    for (train, val) in cv.split(X, y):\n",
    "        #print(np.sum(y[train]),np.sum(y[val],len(y))\n",
    "        foldNum = foldNum + 1\n",
    "\n",
    "        # Modelo arvore\n",
    "        classifier = DecisionTreeClassifier(class_weight='balanced', \n",
    "                                            max_depth=params['max_depth'], \n",
    "                                            min_samples_leaf=params['min_samples_leaf'],\n",
    "                                            min_samples_split=params['min_samples_split'], \n",
    "                                            min_impurity_decrease=params['min_impurity_decrease'], \n",
    "                                            criterion=params['criterion'])\n",
    "        classifier = classifier.fit(X[train], y[train])\n",
    "        probas_ = classifier.predict_proba(X[val])\n",
    "        \n",
    "        #Extraimos[0] pois predict_proba retorna uma coluna pra cada classe, pegamos as probabilidades da 0\n",
    "        probas = [probas_[x][0] for x in range(len(probas_))]\n",
    "\n",
    "        pred = classifier.predict(X[val])\n",
    "        area1 = roc_auc_score(y[val], probas_[:, 1])\n",
    "        area2 = accuracy_score(y[val], pred)  # guarda acuracia\n",
    "\n",
    "        #print('b',np.sum(y[val]),np.sum(pred),len(y[val]))\n",
    "        f1 = f1_score(y[val],pred, average='binary')\n",
    "        #print('w',np.sum(y[val]),np.sum(pred),len(y[val]))\n",
    "        f1w = f1_score(y[val],pred, average='weighted')\n",
    "        \n",
    "        #a guarda o AUC score de cada fold\n",
    "        a.insert(len(a), area1)\n",
    "        #b guarda a acuraria score de cada fold\n",
    "        b.insert(len(b), area2)\n",
    "        #c guarda o F1-binary score de cada fold\n",
    "        c.insert(len(c),f1)\n",
    "        #d guarda o F1-weighted score de cada fold\n",
    "        d.insert(len(d),f1w)\n",
    "\n",
    "        for j in range(len(val)):\n",
    "            #Como cada instancia em df vai estar no conjunto de val em algum fold,\n",
    "            #predlist armazena as predições para todos eles em seus respectivos folds\n",
    "            #probLIst armazena as probabilidades para todos eles em seus respectivos folds\n",
    "            \n",
    "            #val[i] contem o indice em X da i-esima instancia atualmente na validação\n",
    "            #Assim se a instancia indice 3 do dataframe é o primeiro elemento no conjunto de validação atual,\n",
    "            #  estamos fazendo predList[3] = pred[0] já que pred é indexado na ordem de val\n",
    "            predList[val[j]] = pred[j]\n",
    "            probList[val[j]] = probas[j]\n",
    "\n",
    "    if f1i:\n",
    "        return a, np.mean(b), predList, probList,c,d\n",
    "    return a, np.mean(b), predList, probList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(TABLES_PATH + 'totalcx7.csv')\n",
    "df = pd.read_pickle(\"./dfSourceFeatures28Aug2021.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12045, 13)\n",
      "        desinformacao_label  \\\n",
      "count                 12045   \n",
      "unique                    2   \n",
      "top                       0   \n",
      "freq                  10000   \n",
      "\n",
      "                                                      url    subdomain_ip  \\\n",
      "count                                               12045           11964   \n",
      "unique                                              12023             244   \n",
      "top     https://www.progresso.com.br/missao-visao-valo...  204.199.44.211   \n",
      "freq                                                    2            2319   \n",
      "\n",
      "       subdomain_ip_cc subdomain_ip_is_brazil subdomain_ip_is_us  \\\n",
      "count            11964                  11964              11964   \n",
      "unique              12                      2                  2   \n",
      "top                 US                  False               True   \n",
      "freq              6759                   6874               6759   \n",
      "\n",
      "        subdomain_ip_latitude  subdomain_ip_longitude subdomain_as_n  \\\n",
      "count                11964.00                11964.00          11964   \n",
      "unique                  56.00                   62.00             51   \n",
      "top                     37.78                 -122.42          13335   \n",
      "freq                  3694.00                 3692.00           3765   \n",
      "\n",
      "       subdomain_as_cc subdomain_ipcc_equal_ascc  domain_route_hops  \\\n",
      "count            11964                     11964              11964   \n",
      "unique              14                         2                 17   \n",
      "top                 US                      True                  9   \n",
      "freq              9070                      9540               4390   \n",
      "\n",
      "        domain_dns_caa_txt_count  \n",
      "count                      11964  \n",
      "unique                        16  \n",
      "top                            3  \n",
      "freq                        2989  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12045 entries, 0 to 12044\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   desinformacao_label        12045 non-null  object\n",
      " 1   url                        12045 non-null  object\n",
      " 2   subdomain_ip               11964 non-null  object\n",
      " 3   subdomain_ip_cc            11964 non-null  object\n",
      " 4   subdomain_ip_is_brazil     11964 non-null  object\n",
      " 5   subdomain_ip_is_us         11964 non-null  object\n",
      " 6   subdomain_ip_latitude      11964 non-null  object\n",
      " 7   subdomain_ip_longitude     11964 non-null  object\n",
      " 8   subdomain_as_n             11964 non-null  object\n",
      " 9   subdomain_as_cc            11964 non-null  object\n",
      " 10  subdomain_ipcc_equal_ascc  11964 non-null  object\n",
      " 11  domain_route_hops          11964 non-null  object\n",
      " 12  domain_dns_caa_txt_count   11964 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desinformacao_label</th>\n",
       "      <th>url</th>\n",
       "      <th>subdomain_ip</th>\n",
       "      <th>subdomain_ip_cc</th>\n",
       "      <th>subdomain_ip_is_brazil</th>\n",
       "      <th>subdomain_ip_is_us</th>\n",
       "      <th>subdomain_ip_latitude</th>\n",
       "      <th>subdomain_ip_longitude</th>\n",
       "      <th>subdomain_as_n</th>\n",
       "      <th>subdomain_as_cc</th>\n",
       "      <th>subdomain_ipcc_equal_ascc</th>\n",
       "      <th>domain_route_hops</th>\n",
       "      <th>domain_dns_caa_txt_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://g1.globo.com/politica/noticia/2021/07/...</td>\n",
       "      <td>186.192.81.31</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-22.87</td>\n",
       "      <td>-42.35</td>\n",
       "      <td>28604</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.correio24horas.com.br/noticia/nid/...</td>\n",
       "      <td>204.199.44.211</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.92</td>\n",
       "      <td>-43.95</td>\n",
       "      <td>3549</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gazetadopovo.com.br/ideias/capital...</td>\n",
       "      <td>2600:9000:208f:6800:6:45ad:3580:93a1</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47.6</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>16509</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>https://agoranoticiasbrasil.com.br/peritos-da-...</td>\n",
       "      <td>2606:4700:3035::ac43:86e4</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>37.78</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>13335</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>https://g1.globo.com/economia/imposto-de-renda...</td>\n",
       "      <td>186.192.81.31</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-22.87</td>\n",
       "      <td>-42.35</td>\n",
       "      <td>28604</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  desinformacao_label                                                url  \\\n",
       "0                   0  https://g1.globo.com/politica/noticia/2021/07/...   \n",
       "1                   0  https://www.correio24horas.com.br/noticia/nid/...   \n",
       "2                   0  https://www.gazetadopovo.com.br/ideias/capital...   \n",
       "3                   1  https://agoranoticiasbrasil.com.br/peritos-da-...   \n",
       "4                   0  https://g1.globo.com/economia/imposto-de-renda...   \n",
       "\n",
       "                           subdomain_ip subdomain_ip_cc  \\\n",
       "0                         186.192.81.31              BR   \n",
       "1                        204.199.44.211              BR   \n",
       "2  2600:9000:208f:6800:6:45ad:3580:93a1              US   \n",
       "3             2606:4700:3035::ac43:86e4              US   \n",
       "4                         186.192.81.31              BR   \n",
       "\n",
       "  subdomain_ip_is_brazil subdomain_ip_is_us subdomain_ip_latitude  \\\n",
       "0                   True              False                -22.87   \n",
       "1                   True              False                -19.92   \n",
       "2                  False               True                  47.6   \n",
       "3                  False               True                 37.78   \n",
       "4                   True              False                -22.87   \n",
       "\n",
       "  subdomain_ip_longitude subdomain_as_n subdomain_as_cc  \\\n",
       "0                 -42.35          28604              BR   \n",
       "1                 -43.95           3549              US   \n",
       "2                -122.33          16509              US   \n",
       "3                -122.42          13335              US   \n",
       "4                 -42.35          28604              BR   \n",
       "\n",
       "  subdomain_ipcc_equal_ascc domain_route_hops domain_dns_caa_txt_count  \n",
       "0                      True                11                       13  \n",
       "1                     False                12                        3  \n",
       "2                      True                 9                        5  \n",
       "3                      True                 9                        1  \n",
       "4                      True                11                       13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11964, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['desinformacao_label', 'url', 'subdomain_ip', 'subdomain_ip_cc',\n",
       "       'subdomain_ip_is_brazil', 'subdomain_ip_is_us', 'subdomain_ip_latitude',\n",
       "       'subdomain_ip_longitude', 'subdomain_as_n', 'subdomain_as_cc',\n",
       "       'subdomain_ipcc_equal_ascc', 'domain_route_hops',\n",
       "       'domain_dns_caa_txt_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desinformacao_label']= df['desinformacao_label'].astype('bool')\n",
    "df['subdomain_ip_cc']= df['subdomain_ip_cc'].astype('category')\n",
    "df['subdomain_ip_is_brazil']= df['subdomain_ip_is_brazil'].astype('bool')\n",
    "df['subdomain_ip_is_us']= df['subdomain_ip_is_us'].astype('bool')\n",
    "df['subdomain_ip_latitude']= df['subdomain_ip_latitude'].astype('float')\n",
    "df['subdomain_ip_longitude']= df['subdomain_ip_longitude'].astype('float')\n",
    "df['subdomain_as_n']= df['subdomain_as_n'].astype('category')\n",
    "df['subdomain_as_cc']= df['subdomain_as_cc'].astype('category')\n",
    "df['subdomain_ipcc_equal_ascc']= df['subdomain_ipcc_equal_ascc'].astype('bool')\n",
    "df['domain_route_hops']= df['domain_route_hops'].astype('int')\n",
    "df['domain_dns_caa_txt_count']= df['domain_dns_caa_txt_count'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11964 1964\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "label_column_name = 'desinformacao_label'\n",
    "numericalFeatures = ['subdomain_ip_latitude', 'subdomain_ip_longitude','domain_route_hops','domain_dns_caa_txt_count']\n",
    "categorialFeatures = ['subdomain_ip_cc','subdomain_ip_is_brazil','subdomain_ip_is_us', \n",
    "                      'subdomain_as_cc', 'subdomain_ipcc_equal_ascc']\n",
    "nonFeatures = ['url','subdomain', 'subdomain_ip','subdomain_as_n' ]\n",
    "\n",
    "\n",
    "\n",
    "columns = list(df.columns)\n",
    "\n",
    "\n",
    "unwanted_columns = [label_column_name]+nonFeatures + categorialFeatures \n",
    "features_columns = [\n",
    "    item for item in columns if item not in unwanted_columns\n",
    "                   ]\n",
    "print(len(df), np.sum(df[label_column_name]))\n",
    "print(len(features_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature Combinations\n"
     ]
    }
   ],
   "source": [
    "global done\n",
    "global griddone\n",
    "global predone\n",
    "global queue_finished\n",
    "queue_finished = 0\n",
    "predone = 0\n",
    "global s\n",
    "#s = 10000\n",
    "s = 1000\n",
    "totalmodels = 0\n",
    "combs = []\n",
    "done = []\n",
    "griddone = []\n",
    "\n",
    "print('Creating Feature Combinations')\n",
    "numeroMaximoDeFeatures = len(features_columns)\n",
    "for c in range(0,numeroMaximoDeFeatures+1 ):\n",
    "    # print('\\t Size:%d'%c)\n",
    "    if c == 0:\n",
    "        combs.append([])\n",
    "    else:\n",
    "        combs.append(list(set(random_combinations(features_columns, c, s))))\n",
    "    done.append(0)\n",
    "    griddone.append(0)\n",
    "    totalmodels += len(combs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subdomain_ip_latitude', 'domain_route_hops'),\n",
       " ('subdomain_ip_latitude', 'domain_dns_caa_txt_count'),\n",
       " ('domain_route_hops', 'domain_dns_caa_txt_count'),\n",
       " ('subdomain_ip_longitude', 'domain_route_hops'),\n",
       " ('subdomain_ip_longitude', 'domain_dns_caa_txt_count'),\n",
       " ('subdomain_ip_latitude', 'subdomain_ip_longitude')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mmpool(c):\n",
    "    sys.stdout.write(\"Starting MM size %d\\n\" % c)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    comb = combs[c]\n",
    "    \n",
    "    exit1 = open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                 '-size%d-result.csv' % c, 'a+')\n",
    "    exit2 = open(MODELS_PATH + 'MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                 '-size%d-preds.csv' % c, 'a+')\n",
    "\n",
    "    a = eval_panel_platelabel(df, comb, c, exit1, exit2)\n",
    "\n",
    "    global queue_finished\n",
    "    queue_finished += 1\n",
    "    exit1.close()\n",
    "    exit2.close()\n",
    "    return(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directories\n",
      "Starting MM size 1\n",
      "Starting MM size 2ess: 100.000% (4/4) [Elapsed: 0s | Predicted 0s | Avg: 0s]ed 638s | Avg: 0s]\n",
      "Starting MM size 3ess: 100.000% (6/6) [Elapsed: 0s | Predicted 0s | Avg: 0s]ted 1013s | Avg: 0s]\n",
      "Starting MM size 4ess: 100.000% (4/4) [Elapsed: 0s | Predicted 0s | Avg: 0s]ed 709s | Avg: 0s]\n",
      "0.8386126651996676ess: 100.000% (1/1) [Elapsed: 0s | Predicted 0s | Avg: 0s]ed 212s | Avg: 0s]\n",
      "0.8100053610375448\n",
      "0.9870822158825362\n",
      "0.9870822158825362\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    print('Creating Directories')\n",
    "    if (not os.path.isdir(MODELS_PATH + 'MultipleModels_DecisionTrees')):\n",
    "        os.mkdir(MODELS_PATH + 'MultipleModels_DecisionTrees')\n",
    "\n",
    "    #for c in range(1, numeroMaximoDeFeatures+1):\n",
    "    #Deletamos a ultima linha pro caso de ter rolado uma execução parcial\n",
    "    for c in range(1, 5):\n",
    "        if os.path.isfile('MultipleModels_DecisionTrees/' + TASK_NAME + '-size%d-result.csv' % c):\n",
    "            delete_last_lines('MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                              '-size%d-result.csv' % c)\n",
    "            delete_last_lines('MultipleModels_DecisionTrees/' + TASK_NAME +\n",
    "                              '-size%d-preds.csv' % c)\n",
    "    results = []\n",
    "    for c in range(1,5):\n",
    "        res = run_mmpool(c)\n",
    "        results.append(res)\n",
    "        \n",
    "        \n",
    "#     pool = Pool(processes=10)\n",
    "#     #results = pool.map(run_mmpool, list(range(1, numeroMaximoDeFeatures+1)))\n",
    "#     results = pool.map(run_mmpool, list(range(1, 3)))\n",
    "#     time.sleep(10)\n",
    "#     pool.join()\n",
    "\n",
    "for i in range(0, len(results)):\n",
    "    print(np.max(results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
